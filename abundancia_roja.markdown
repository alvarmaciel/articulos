---
layout: post
title: "Plataformas para la abundancia roja"
author: "Nick Dyer-Witheford"
license: http://endefensadelsl.org/ppl_deed_es.html
---

Plataformas para la abundancia roja
===================================

> Publicado originalmente en [Culture Machine Vol.
> 14](http://www.culturemachine.net/index.php/cm/issue/view/25) (2013)
> como _"Red Plenty Platforms"_.  Publicado bajo la Licencia de
> Producción de Pares con permiso del autor.

Introducción: Abundancia roja
-----------------------------

Poco después de la gran caída de Wall Street del 2008, una novela acerca
de eventos históricos oscuros y remotos proveía un inesperado punto de
discusión sobre la crisis en marcha.  Abundancia roja, de Francis
Spufford (2010), ofrecía un recuento ficcionalizado del intento fallido
de los cibernéticos soviéticos de los '60 por establecer un sistema
completamente computarizado de planificación económica.  Mezclando
figuras históricas --Leonid Kantorovich, inventor de las ecuaciones de
programación lineal, Sergei Alexeievich Lebedev, pionero del diseño de
computadoras soviéticas, Nikita Khrushchev, Secretario General del
Partido Comunista-- con imaginarias y poniéndolas en acción en los
pasillos del Kremlin, colectivos rurales, fábricas industriales y la
ciudad científica siberiana de Akademgorodok, Abundancia roja tuvo éxito
en la improbable misión de convertir la planificación cibernética en un
libro atrapante.  Pero el interés que atrajo por parte de economistas,
informáticas y activistas políticas no fue solo por la narrativa
científica y la intriga política.  También le debió mucho al momento en
que se publicó.  Al aparecer en medio de la austeridad y el desempleo,
con el mercado global todavía al borde del colapso, Abundancia roja
puede interpretarse de distintas formas: a) como un cuento con moraleja
que al retrotraernos a las debacles soviéticas nos recuerda que el
capitalismo sigue existiendo, aun cuando no funcione del todo bien ("no
hay otra alternativa"); o b) contraintuitivamente, como una recolección
de potencialidades no realizadas, no solo susurrando el pintoresco
eslogan altermundialista "otro mundo es posible", sino lo que David
Harvey [-@harvey-2010] identifica como la otra posibilidad, más fuerte
y subversiva, la del "otro comunismo".

Este artículo toma la novela de Spufford como el punto de partida desde
el que examinar las plataformas informáticas que serían necesarias para
una "abundancia roja" contemporánea.  No es una discusión sobre los
méritos o deméritos del hacktivismo, la desobediencia digital, los
entramados electrónicos de las luchas, _twits_ en las calles o las
revoluciones por Facebook, sino del comunismo digital.  Este tema ya ha
sido tratado por una ola de repensadoras de la vida luego del
capitalismo iniciada por la implosión de la URSS en 1989, en propuestas
como "economía participativa" [@albert-hahnel-1991], un "nuevo
socialismo" [@cockshott-cottrell-1993], "socialismo del siglo XXI"
[@dieterich-2006] o forma de "_commonwealth_" [@hardt-negri-2009].  Al
contrario de estas fuentes, este ensayo no intenta proveer cianotipos
detallados, a menudo competitivos, para una sociedad nueva, sino lo que
Greg de Peuter llamaba (en una conversación privada), "rojotipos", es
decir orientaciones aproximativas a posibilidades revolucionarias.

Al discutir informática y comunismo resulta casi imposible escapar a las
acusaciones de abandono de las luchas por un determinismo mecanicista.
Ciertamente todos los modelos automáticos, teleológicos
y evolucionistas, incluyendo las coreografías esquemáticas de fuerzas
y relaciones de producción, deben ser rechazados.  Resulta tan
importante, sin embargo, como evitar por el contrario un determinismo
humanista, que exagera la autonomía y el privilegio ontológico del
"hombre contra la máquina".  Aquí, los modos de producción y las luchas
que los convulsionan, son entendidos como combinaciones de agentes
humanos y mecánicos, enredados, híbridos y co-determinados "ensamblajes
deleuzo-delandianos" [@thorburn-2013].

Es por esto que la estimación que me enviara Benjamin Peters,
historiador de la cibernética soviética, comparando las máquinas que los
planificadores de Abundancia roja tenían a disposición en, digamos 1969,
con la computadora mas rápida de 2019 arroja que el poder de
procesamiento de esta última representará "aproximadamente un aumento de
100 mil millones de veces en operaciones por segundo" resulta excitante,
un hecho que es, como remarca Peters, "no significativo en sí mismo pero
aun así sugestivo".  El argumento que sigue explora esta sugestividad.
Este artículo trata sobre la línea más directa en la continuidad de la
cibernética soviética en cuanto a teorización de formas de planificación
económica basada en algoritmos de tiempo de trabajo y supercomputación.
Ademas discute las preocupaciones sobre el autoritarismo en la
planificación centralizada y como es afectado por los medios sociales
y los agentes de software, antes de pasar a considerar si la
planificación se vuelve redundante en un mundo de autómatas, junto con
la copia y la replicación.  Como respuesta parcial a la última pregunta,
este artículo recorre el rol de la cibernética dentro de la bio-crisis
planetaria, concluyendo con algunas observaciones generales sobre la
cibernética en el "horizonte comunista" actual [@dean-2012].  Primero,
no obstante, revisa algunos de los problemas, tanto prácticos como
teóricos, con los que se encontraron los planificadores soviéticos de
Abundancia roja.


¿El capitalismo es una computadora?
-----------------------------------

Las filósofas digitales sugieren que el universo podría ser una
simulación por computadoras programada por extraterrestres.  Sin
involucrarse en esta posición, hay motivos para considerar una
proposición intermedia, es decir que el capitalismo es una computadora.
Esta es la contienda implícita en una de las más serias respuestas
intelectuales al pensamiento comunista, "el problema del cálculo
socialista", formulado por economistas de la escuela de Austria como
Ludwig von Mises [-@mises-1935] y Frederick Hayes [-@hayes-1945].
Escribiendo en el período definido por el éxito de la revolución rusa,
estos economistas atacaron las premisas y la factibilidad de la economía
centralmente planificada.  Todos los sistemas sociales, reconocían,
necesitan una forma de planificación de recursos.  El mercado, sin
embargo, funciona como un plan distribuido, espontáneo, emergente
y no-coercitivo --lo que Hayek llamó la "catalaxia" [-@hayek-1976].  Los
precios proveen una señal sinóptica y abstracta sobre condiciones
y necesidades cambiantes y heterogéneas a los que la inversión
empresarial responde.  Una economía comandada, en contraste, debe ser
a la vez despótica e impráctica, porque el cálculo de una distribución
óptima de recursos escasos depende de innumerables conocimientos locales
sobre las necesidades de consumo y las condiciones de producción que
ningún método central de reporte podría compilar y evaluar.

Por lo tanto los economistas austríacos ofrecían una versión actualizada
de la "mano invisible" del capital de Adam Smith, ahora reconvertida en
un sistema de información cuasi cibernético:

> Es más que metafórico describir el sistema de precios como una especie
> de maquinaria para registrar el cambio, o como un sistema de
> telecomunicaciones que permite a las productoras individuales observar
> algunos puntos como una ingeniera observa las indicaciones de un
> medidor, para poder ajustar sus actividades a cambios de los que no
> podrían saber más que lo que se refleja en el movimiento de precios
> [@hayek-1945].

Aunque se refería a las telecomunicaciones y la ingeniería durante el
ultimo año de la Segunda Guerra Mundial, Hayek bien podría haberse
referido a las gigantes _mainframes_ del Proyecto Manhattan, porque lo
que estaba proponiendo era que el mercado actúa como un motor de cálculo
automático: una computadora.

Este es, sin embargo, un argumento contra el socialismo de doble filo.
Si el mercado actúa como una computadora, ¿por qué no reemplazarlo por
una? Si la planificación centralizada sufría de un problema de cálculo,
¿por qué no resolverla con máquinas de cálculo reales?  Este fue
precisamente el argumento del oponente de Hayek, el economista Oskar
Lange, que refiriéndose en retrospectiva al debate sobre el "cálculo
socialista", remarcaba: "Hoy mi tarea hubiera sido mucho más simple.  Mi
respuesta a Hayek hubiera sido: ¿cuál es el problema?  Pongamos las
ecuaciones simultáneas en una computadora electrónica y obtendremos la
solución en menos de un segundo" [@lange-1967].  Este era el proyecto de
las cibernéticas de Abundancia roja, un proyecto motivado por la
realización de que la aparentemente exitosa economía industrial
soviética, pese a sus triunfos en los '40 y '50, se estaba estancando en
medio de la incoherencia organizativa y los cuellos de botella
informacionales.

Su esfuerzo dependió de una herramienta conceptual, la tabla de
entrada-salida, cuyo desarrollo está asociado a dos matemáticos rusos:
el emigrado Wassily Leontief, que trabajó en EEUU y el soviético
Kantorovich, protagonista de _Abundancia roja_.  Las tablas de
entrada-salida --que recientemente se han descubierto parte del
fundamento intelectual del algoritmo _PageRank_ de Google
[@franceschet-2010]-- trazan la compleja interdependencia de una
economía moderna al mostrar cómo las salidas de una industria (por
ejemplo el acero o el algodón) proveen las entradas para otras
(automóviles o ropa), de forma que puede estimarse el cambio en la
demanda resultante de un cambio en la producción de bienes.  En los '60
estas tablas eran un instrumento aceptado por las organizaciones
industriales de gran escala: el trabajo de Leontief incidió en la
logística del bombardeo masivo a Alemania por parte de las fuerzas
aéreas estadounidenses.  No obstante, se creía que la complejidad de una
economía nacional completa impedía su aplicación a tal nivel.

Las científicas informáticas soviéticas se propusieron resolver este
problema.  Ya en los '30, Kantorovich había mejorado las tablas de
entrada-salida con el método matemático de programación lineal, que
estimaba, u "optimizaba", la mejor combinación de técnicas de producción
necesarias para un objetivo.  Las cibernéticas de los '60 intentaron
implementar ese descubrimiento a escala masiva, estableciendo una
infraestructura informática moderna capaz de procesar los millones de
cálculos requeridos por _Gosplan_, la Mesa Estatal de Planificación que
supervisaba los planes quinquenales económicos.  Luego de una década de
experimentación, su intento colapsó, frustrado por el lamentable estado
de la industria informática soviética --que al estar dos décadas
atrasada con respecto a los EEUU, se perdió la revolución de la
computadora personal y no desarrolló un equivalente a Internet.  Por lo
tanto era totalmente inadecuado para lo que se proponía lograr.  Además
tenía la oposición de la _nomenklatura[^ndt-nomenklatura]_, que veía en
la planificación informática una amenaza a su poder burocrático y apuró
el abandono del proyecto [@castells-2000; @gerovitch-2008; peters-2012].

[^ndt-nomenklatura]: Lista o clase de personas selectas que conformaban
 el alto mando de la burocracia sovietica. _(Nota de traducción)_

Este no fue el único proyecto sobre "cibernética revolucionaria" del
siglo XXI.  Igual de remarcable fue el intento del gobierno de Salvador
Allende en Chile por introducir una versión descentralizada de
planificación electrónica, el Proyecto _Cybersyn_ [@medina-2005].
Liderado por el cibernético canadiense Stafford Beer, fue concebido como
un sistema de comunicación y control que habilitaría al gobierno
socialista a recolectar información económica y presentarla a quienes
tomaban las decisiones políticas, aun cuando incluía en su tecnología
salvaguardas contra la microgestión estatal y estímulos para discusiones
multilaterales sobre la planificación.  Este fue un intento de
ingeniería sociotécnica para el socialismo democrático que hoy en día
parece más atractivo que las maniobras post-estalinistas de las
planificadoras soviéticas.  Pero se encontró con un destino más brutal:
el Proyecto _Cybersyn_ fue exterminado por el golpe pinochetista de
1973.

La falla de la URSS por adaptarse al mundo del software y las redes
contribuyó a su derrota económica y militar ante EEUU.  Su
desintegración, donde, como demostraba Alec Nove [-@nove-1983], los
cuellos de botella de información y la falsificación de reportes jugaron
un rol preponderante, pareció reivindicar a los economistas austriacos.
Las alabanzas de Hayek a la catalaxia del mercado se volvieron centrales
al "pensamiento colectivo neoliberal" [@mirowski-2009] que lideró la
marcha victoriosa del capitalismo global.

La presión combinada del desastre práctico de la URSS y el argumento
teórico de la escuela de Austria ejerció una fuerza enorme dentro de lo
que quedaba de la izquierda, presionándola para reducir y redefinir el
límite de sus aspiraciones radicales a, como mucho, una economía de
empresas colectivamente apropiadas, coordinadas por señales de precios.
Las muchas variantes de tal "socialismo de mercado" han provocado el
rechazo de las marxistas que se resisten al intercambio de mercancías.
Tal vez porque le otorgan al mercado las mismas funciones de
procesamiento automático de información que los economistas austríacos
y las socialistas de mercado, pueden tocar temas como la innovación
tecnológica o la disponibilidad de datos públicos, pero no parecen
involucrarse profundamente con las potencialidades de la computación
moderna.

En la actualidad y después de la crisis, decir que los mercados son
máquinas infalibles de información puede sonar menos creíble que un
cuarto de siglo atrás.  El parasitario robo energético que subyace a las
transmisiones de señales de precios (es decir la explotación en el
momento de la producción), la incapacidad de los intercambios
individuales de mercancías para registrar las consecuencias colectivas
(las llamadas "externalidades") y la recursividad de un sistema
crematístico[^ndt-crematístico] que se vuelve sobre sí mismo en la
especulación financiera destacan cada vez mas en el medio de la
implosión económica y ecológica del capital global.  Pero la
identificación de estas fallas no excusa a las comunistas de especificar
cómo otro sistema de distribución de recursos podría funcionar, sin caer
en la "servidumbre" de la subyugación estatista que predijo Hayek
[-@hayek-1994].

[^ndt-crematístico]: Conocimientos y estudios referidos a la producción
  y la distribución de la riqueza. _(Nota de traducción)_


Algoritmos laborales
--------------------

A pesar de la caída del socialismo real, la idea de la planificación
central computarizada continuó siendo desarrollada por pequeños grupos
de teóricas, que han avanzado su alcance conceptual mas allá de lo que
habían intentando las cibernéticas soviéticas.  Dos escuelas han sido de
fundamental importancia:  el "Nuevo Socialismo" de los científicos
informáticos escoceses Paul Cockshott y Alan Cottrell
[-@cockshott-cottrell] y la "Escuela de Bremen" alemana, incluyendo
a Peter Arno [-@arno-2002] y Heinz Dieterich [-@dieterich-2006], el
último de los cuales es un militante del "Socialismo del Siglo XXI" al
estilo venezolano.  Estas tendencias han convergido recientemente
[@cockshott-cottrell-dieterich-2010].  Sin embargo, como muy pocas obras
de la Escuela de Bremen han sido traducidas, el foco aquí estará puesto
sobre el Nuevo Socialismo de Cockshott y Cottrell.

La marca distintiva del proyecto del Nuevo Socialismo es el rigor
marxista clásico.  De esta forma, la planificación por supercomputadoras
del siglo XXI sigue al pie de la letra la lógica de la Crítica al
Programa de Gotha [@marx-1970] de finales del siglo XIX, que sugería que
en el primer estadío del comunismo, antes que las condiciones de
abundancia permitan el "a cada cual según su necesidad", la remuneración
sería determinada por la cantidad de horas socialmente necesarias
requeridas para la producción de bienes y servicios.  En el espacio de
trabajo capitalista, las trabajadoras son pagadas por la reproducción de
su capacidad de trabajo y no por el trabajo realmente extraído de ellas.
Esto es lo que permite al capitalismo asegurarse la plusvalía.

La eliminación de este estado de hechos, dicen Cockshott y Cottrell,
requiere nada menos que la abolición del dinero --es decir, la
eliminación del medio general de intercambio que, a través de una serie
de metamorfosis desde y hacia la forma mercancía, crea el valor
auto-expandible que es el capital.  En su Nuevo Socialismo, el trabajo
sería remunerado en certificados de trabajo.  Una hora de trabajo podría
ser intercambiada por aquellos bienes que requieran la misma cantidad de
tiempo social promedio para ser producidos.  Los certificados quedarían
extintos en el acto, siendo incapaces de circular ni ser utilizados para
especular.  Como las trabajadoras son retribuidas con el valor social
completo, no habría ganancias ni capitalistas para dirigir la
distribución de los recursos.  De todas formas las trabajadoras pagarían
un impuesto que establezca un pozo de recursos en tiempo productivo,
disponible para las inversiones sociales hechas por mesas de
planificación cuyos mandatos serían establecidos por decisiones
democráticas sobre objetivos sociales generales.

El tiempo de trabajo provee "la unidad objetiva de valor" del Nuevo
Socialismo [@cockshot-cottrell-2003].  En este punto son invocadas las
capacidades de la tecnología informática.  Tal sistema requeriría la
enumeración del tiempo de trabajo utilizado, tanto directa como
indirectamente, en la creación de bienes y servicios, para evaluar la
cantidad de certificados necesarios y también para habilitar la
planificación económica.  La tabla de entrada-salida reaparece, poniendo
especial atención en el tiempo de trabajo, tanto como una entrada
necesaria para la producción de bienes como una salida que requiere a su
vez las entradas del entrenamiento y la educación.  No obstante, aquí
las Nuevas Socialistas deben confrontar una objeción básica.  Desde la
caída de la URSS se ha aceptado convencionalmente que la escala del
procesamiento de información que intentaron las cibernéticas soviéticas
era simplemente demasiado grande.  En los '80, Nove [-@nove-1983]
sugería que tal esfuerzo, involucrando la producción de unos doce
millones de ítems discretos, demandaría una complejidad de cálculos de
entrada-salida imposible aun con computadoras.  Esto fue repetido en las
discusiones recientes sobre _Abundancia roja_, donde las críticas de la
planificación central sugerían que aun con la "máquina de escritorio"
actual, resolver las ecuaciones tomaría "algo así como mil años"
[@shalizi-2012].

La respuesta de Cockshott y Cottrell involucra más herramientas, tanto
conceptuales como técnicas.  Los avances teoréticos son tomados de ramas
de la ciencia informática que tratan con la abreviación de los pasos
discretos necesarios para completar una ecuación.  Tal análisis,
sugieren, demuestra que las objeciones de las oponentes están basadas en
métodos "patológicamente ineficientes" [@cockshott-2012].  La estructura
de entrada-salida de la economía es, dicen, "dispersa" --es decir, solo
una mínima fracción de los bienes son utilizados directamente para
producir cualquier otro bien.  No todo es una entrada para todo el
resto:  el yogur no es utilizado para producir acero.  La mayor parte de
las ecuaciones que se invocan para sugerir complejidades insuperables
son por lo tanto gratuitas.  Es posible diseñar un algoritmo para
encontrar atajos en las tablas de entrada-salida, ignorando las entradas
en blanco, repitiendo el proceso iterativamente hasta que se alcanza un
resultado con un orden de precisión aceptable.

El tiempo podría reducirse masivamente por la velocidad de procesamiento
computacional predicha por la Ley de Moore.  Sugerir que la
planificación económica de alto nivel se realice en una "máquina de
escritorio" resulta poco sincero.  De acuerdo con una comunicación
electrónica con Benjamin Peters, en 1969 (la época de _Abundancia Roja_)
el "caballo de tiro indisputable" de la economía informática soviética
era la BESM-6 ("_bolshaya electronicheskaya schetnaya mashina_",
literalmente "gran máquina calculadora electrónica"), que podría operar
a una velocidad de 800.000 flops u "operaciones flotantes por segundo",
es decir, a 8 megaflops, o 10^6^ flops.  En 2013, no obstante, las
supercomputadoras utilizadas en el modelado climático, testeo de
materiales y cálculos astronómicos generalmente sobrepasan los 10
cuadrillones de flops o diez "teraflops".  La mayor al momento de
escribir este articulo es la Titán de Cray, en el _Oak Ridge National
Laboratory_, alcanzando unos 17,6 petaflops, es decir 10^15^ flops
[@wikipedia-2013].  Las computadoras con una capacidad de 1 "exaflop",
o 10^18^ flops, han sido predichas para el 2019 en China
[@dorrier-2012]. Por lo tanto, como dice Peters [-@peters-2013],
"otorgándole a las soviéticas unos generosos 10^7^ flops en 1969,
podemos encontrar que 10^18^ - 10^7^ = 10^11^ ... es decir un incremento
de 100.000.000.000 de veces".

Con estas capacidades, se vuelve plausible la sugerencia de Cockshott
y Cottrell donde los requerimientos computacionales de la planificación
económica de gran escala pueden ser manejados por instalaciones
comparables a las de las estaciones meteorológicas actuales.  El
"problema de cálculo", no obstante, no solo involucra el procesamiento
de los datos sino también su disponibilidad.  La crítica de Hayek no
pasa solo por la velocidad imposible con la que las planificadoras
centralistas deberían procesar las cifras económicas, sino que esos
números no existen hasta el momento de la fijación del precio, que
provee una medida de otra forma ausente de performance de la producción
y actividad del consumo.  De nuevo, Cockshott y Cottrell sugieren que la
respuesta está en el uso de computadoras para la recolección de
información económica.  Escribiendo en los '90 e invocando los niveles
de infraestructura de red disponibles en la Inglaterra del momento,
sugieren un sistema de coordinación compuesto por unas pocas
computadoras personales en cada unidad productiva, que usando paquetes
de programación estándar procesarían los datos de la producción local
y los enviarían por "teletipo"[^ndt-Teletipo] a una instalación de
planificación central, que cada 20 minutos respondería por señales de
radio con los datos ajustados estadísticamente, para ser reutilizados en
el nivel local. Este escenario recuerda mucho al destartalado
tecno-futurismo que nos muestra Terry Gilliam en _Brazil_.  Para
actualizar a las Nuevas Socialistas deberíamos referirnos más bien a la
iconoclasta visión de Fredric Jameson sobre _Wal-Mart_ como "la silueta
del futuro utópico avecinándose entre la niebla" [-@jameson-2009].  El
punto es que si por un momento ignoramos la explotación de trabajadoras
y proveedoras, _Wal-Mart_ es una entidad cuyos colosales poderes
organizativos modelan los procesos planificativos necesarios para elevar
los estándares globales de vida.  Como Jameson reconoce y otras autoras
documentan en detalle [@lichtenstein-2006], este poder descansa sobre
las computadoras, las redes y la información.  Para mediados de los
2000, los centros de datos de _Wal-Mart_ procesaban activamente más de
680 millones de productos distintos por semana y más de 20 millones de
transacciones de venta por día, todo esto facilitado por un sistema
computacional solo seguido en capacidad por el del Pentágono.  Los
escáneres de código de barras y las computadoras en los puntos de venta
identifican cada ítem vendido y almacenan su información.  Las
comunicaciones satelitales vinculan a las tiendas con el sistema central
y esta a su vez con las computadoras de los proveedores, posibilitando
el re-abastecimiento automático.  La adopción temprana de los códigos
universales de producto llevaron a un "estadío más alto" requiriendo que
todos los productos lleven etiquetas de Identificación por Radio
Frecuencia (RFID) para permitir el seguimiento de mercancías,
trabajadoras y consumidoras dentro y más allá de la cadena de suministro
global.

[^ndf-Teletipo]: Red similar a la telefónica, utilizada para la
  transmisión de datos mecanográficos. _(Nota de traducción)_

Wal-Mart resulta importante porque se encuentra "en la vanguardia de un
cambio[^shift] sísmico en el imaginario corporativo".  Es un cambio que
vincula la noción de "revolución de la logística" con la "producción
justo a tiempo" y "aprovecha las tecnologías digitales y cibernéticas
emergentes para la gestión de la producción, distribución y ventas de la
forma más veloz y eficiente" [@haiven-stonemouth-2009].  Este cambio es
estimulado por la emergencia de la "Internet de las cosas", que
relaciona la información digital con las cosas físicas del mundo real
a través de una red de productos, usuarias y ubicaciones instrumentadas
por sensores.  Es habilitada por la difusión de redes inalámbricas 4G
y almacenamiento de datos bajo demanda en "la nube" de empresas como
Amazon.  Y especialmente, es habilitada por el moderno protocolo de
Internet llamado IPv6, que aumenta la cantidad de direcciones
disponibles proveyendo identificadores digitales únicos para una
cantidad de cosas "verdaderamente gigantesca, en el orden de los 340
miles de miles de miles de miles de millones".  Esta comunicación de
dispositivo a dispositivo probablemente exceda el volumen de datos del
tráfico entre personas en Internet [@economist-2012].  Como observa
Benjamin Bratton [-@bratton-2013], con tal capacidad de
direccionamiento, combinada con la codificación digital comprimida
a niveles sub-microscópicos, habilita una capacidad virtualmente
infinita para la identificación no solo de cosas y de personas, sino
también de los más elementales componentes de sus relaciones.

[^shift]: _Shift_ en el original, como en cambio de paradigma (Nota de
la traducción.)

Por lo tanto la trayectoria tanto de la velocidad del procesamiento de
información como de la capacidad de recolección de datos apunta a la
supresión del "problema de cálculo socialista".  Sin embargo, hablar de
planificación en contextos panopticistas significa invocar
inevitablemente el miedo al control estatal omniciente.  Las Nuevas
Socialistas provienen de un linaje marxista-leninista de vanguardia, con
una perspectiva "jacobina" auto-asumida
[@cockshott-cottrell-dieterich-2011].  Para empezar a considerar cómo la
planificación cibernética podría desarrollarse en modos más
transparentes y participativos, tenemos que enfocarnos en tradiciones
comunistas diferentes.


Agentes comunistas
------------------

Históricamente, la tendencia marxista anti-estatista se ha dado
mayormente bajo la tradición de los "consejos obreros", que contra los
poderes del Partido y del Estado han insistido en el rol de las
asambleas en el lugar de trabajo como espacio para la toma de
decisiones, la organización y el poder.  En el ensayo (antediluviano
para los estándares digitales) _Los consejos obreros y la economía de la
sociedad autogestionada_, que fue escrito en 1957 pero re-publicado en
1972 inmediatamente después del aplastamiento soviético de los consejos
obreros húngaros, Cornelius Castoriadis señalaba la frecuente
incapacidad de esta tradición de abordar los problemas económicos de una
"sociedad totalmente auto-gestionada".  La pregunta, decía, debía
situarse "firmemente en la era de la computadora, de la explosión del
conocimiento, de la onda de radio y la televisión, de las matrices de
entrada-salida", abandonando "las utopías socialistas o anarquistas de
años atrás" porque "las infraestructuras tecnológicas [...] son tan
inconmensurablemente distintas que cualquier comparación resulta
insignificante" [@castoriadis-1972].  Como los planificadores de
Abundancia roja, Castoriadis imagina un plan económico determinado por
tablas de entrada-salida y ecuaciones de optimización que gobiernen la
distribución de recursos (por ejemplo el balance entre inversión
y consumo), pero cuya implementación se encuentre en manos de los
consejos locales.  El punto más importante, sin embargo, es que debería
haber varios planes disponibles para la elección colectiva.  Esta sería
la misión de la "fábrica de planificación", una "empresa específica
altamente mecanizada y automatizada" usando "una computadora" cuya
"memoria" podría "almacenar los coeficientes técnicos y la capacidad
productiva inicial de cada sector" [@castoriadis-1972].  Esta fábrica
central estaría soportada por otras estudiando las implicaciones
regionales de planes específicos, las innovaciones tecnológicas y las
mejoras algorítmicas.  La "fábrica de planificación" no determinaría
cuáles objetivos sociales deberían adoptarse sino que solo generaría
opciones, analizaría consecuencias y después de que uno de sus planes
haya sido democráticamente seleccionado, lo actualice y revise según sea
necesario.  Castoriadis estaría de acuerdo con Raymond Williams
[-@williams-1983] cuando observaba que no hay nada intrínsecamente
autoritario sobre la planificación, siempre y cuando exista más de un
plan.

Esta concepción temprana de la auto-gestión cibernética es precursora de
una visión post-capitalista más reciente, la "economía participativa"
o _Parecon_ de Michael Albert y Robin Hahnel [-@albert-hahnel-1991].  La
economía participativa también emerge de la tradición de los consejos
obreros, aunque de una línea de pensamiento anarquista antes que
marxista.  Su obra es famosa por el modelo de "planificación
participativa decentralizada" [@albert-2003] como alternativa tanto
a los mecanismos del mercado como a la planificación centralizada.  Los
consejos son, de nuevo, las unidades societarias básicas para la
decisión democrática, pero en la _Parecon_ se incluyen los consejos de
consumidoras junto con los de obreras.  La distribución de recursos está
determinada por la puja entre estas organizaciones por diferentes
niveles de producción y consumo, que luego de una serie de rondas de
negociación son reconciliadas progresivamente por las Mesas de
Facilitación de Iteraciones.  En las etapas sucesivas del proceso de
planificación, los consejos obreros y de consumo son alentados por las
MFI a revisar sus propuestas con conocimiento de las posiciones mutuas,
hasta que exista una convergencia tal que se pueden someter varios
planes posibles a votación.

La _Parecon_ ha sido tema de considerable controversia.  Una de las
objeciones más frecuentes es que ejemplifica el problema que Oscar Wilde
identificaba al remarcar que "el socialismo es una buena idea pero toma
demasiadas tardes", es decir que parece requerir reuniones infinitas.
Hahnel [-@hahnel-2008] sugiere que el incremento de la interactividad
social es una característica positiva de la _Parecon_, a la vez que su
complejidad no debería ser necesariamente mayor que muchos de los
requisitos rutinarios de la vida diaria bajo el capitalismo  --hacer las
compras, pagar los impuestos, llevar finanzas, etc.  Pero pareciera que
conducir los ciclos iterativos y multi-nivel de planificación a una
velocidad suficiente como para lograr algo podría demandar una
infraestructura de red muy sofisticada y un alto nivel de participación
mediada por la tecnología, es decir bancos de datos extensivos accedidos
por consejos y personas individuales, tarjetas electrónicas para la
medición del trabajo y el consumo, software para la preparación de
propuestas y sistemas de inventario justo-a-tiempo para la producción
[@albert-2003].

De hecho la _Parecon_ parece reclamar un desarrollo digital posterior
a su propuesta:  los _social media_.  Una sociedad donde la
planificación colectiva sea participativa, informada, democrática
y oportuna requeriría plataformas comunicativas rápidas, variadas
e interactivas donde las propuestas pudieran circular, ser respondidas
breve o extensivamente, identificando tendencias, estableciendo
reputaciones, generando revisiones y amendas, etc.  Demandaría de hecho
que _Facebook_, _Twitter_, _Tumblr_, _Flickr_ y otras plataformas de la
web 2.0 no solo se conviertan en operaciones auto-gestionadas por sus
trabajadoras (incluyendo a las prosumidoras no pagas), sino también en
foros para la planificación, en _Gosplán_ con _tuits_ y _likes_.  Además
debemos pensar en estos órganos transformados hacia direcciones ya
experimentadas por las redes sociales alternativas como
[_Diaspora_](https://diasporafoundation.org/),
[_Crabgrass_](https://crabgrass.riseup.net/)
o [_Lorea_](https://lorea.org/) y liberados del ánimo de lucro y el
control centralizado, tomando formas "distribuidas" y "federadas"
[@cabello-2013; @sevignani-2013]. Convirtiéndose, como proponen Hu
y Halpin [-@hu-halpin-2013], en redes cuyo formato mismo priorice los
proyectos grupales sobre las identidades individuales, o como
plataformas de "individuación colectiva".  No tanto _social media_ sino
más bien _council media_[^council].

[^council]: _Council_ significa consejo en inglés (nota de la
traducción.

Aun así la idea de que todo el mundo se encuentre observando la pantalla
de su celular a riesgo de perder, no ya un mensaje de _Facebook_, sino
la votación de la enésima iteración del plan participativo duplica las
características no atractivas de la vida diaria bajo el capitalismo de
alta tecnología.  Entonces debemos especular más allá y sugerir que lo
que la planificación decentralizada realmente necesita no son los
_council media_ sino las agentes comunistas, las agentes comunistas de
software.  Las agentes de software son entidades complejas programadas
capaces de actuar "con un cierto grado de autonomía [...] en nombre una
usuaria (u otro programa)" [@wikipedia-2013b].  Tales agentes
manifiestan "orientación a objetivos, selección, priorización
e iniciación de tareas".  Pueden activarse a sí mismas, analizar
y reaccionar al contexto, exhibir aspectos de inteligencia artificial,
como el aprendizaje y pueden comunicarse y cooperar con otras agentes
[@wikipedia-2013].

Comercialmente, las "agentes de puja" por software son capaces de
superar consistentemente a agentes humanas tanto que "las humanas están
al borde de perder su estatus como la única especie económica del
planeta" [@kephart-2002].  La habilidad de tales entidades de crear una
"competencia perfecta" en los mercados electrónicos las ha convertido en
las favoritas de los economistas influenciados por la escuela de Austria
[@mirowski-2002].  En tanto compradoras y vendedoras pre-programadas
capaces de procesar grandes cantidades de datos de mercado, las agentes
de software han transformado el comercio electrónico por su habilidad
para buscar rápidamente en Internet, identificar las mejores ofertas,
agregar la información para sus usuarias o, de hecho, realizar compras
autónomamente.  Sin embargo, el espacio en el que tales agentes son
excelentes es en el sector financiero, donde la compraventa de alta
frecuencia depende enteramente de "bots" de software capaces de
responder a posibilidades de arbitraje en cuestión de milisegundos.

No podemos evitar preguntarnos qué pasaría si las agentes de software
pudieran manifestar una política diferente.  Tomando en cuenta que los
modelos multi-agente pueden pensarse como un medio para responder
problemas de distribución de recursos, Don Greenwood [-@greenwood-2007]
sugiere que podrían orientarse a resolver el "problema de cálculo
socialista".  En tanto herramientas de planificación, los sistemas
multi-agente tienen la ventaja sobre los mercados reales de que "los
objetivos y restricciones están pre-especificados por quien diseña del
modelo" [@greenwood-2007].  Es posible diseñar agentes con objetivos
macro que involucren más que la sola maximización del interés
individual.  La igualdad y la sostenibilidad ambiental son dos
principios "de bienestar" que las economistas han experimentado con
incorporar.

Tal vez debamos concebir los ciclos de decisión de la planificación
democrática como no solo sujetos a debate y deliberación en los _social
media_ sino también parcialmente delegados a una serie de agentes de
software comunistas, que absorban las demandas atencionales del proceso,
corriendo al paso de los algoritmos de alta compraventa, barrenando a
través de redes ricas en datos, haciendo recomendaciones a las
participantes humanas ("si te gustó la geo-ingeniería más la
nano-tecnología pero el plan quinquenal no nuclear, también te podría
gustar..."), comunicándose y cooperando entre sí en diferentes niveles,
pre-programadas para umbrales y configuraciones de decisión específicas
("mantener las emisiones de CO2 por debajo de las 300 partes por millón,
incrementar los ingresos en el quintil inferior... y no aumentar la
cantidad de horas de trabajo necesarias para que podamos tomar café").
En la era de las máquinas autónomas, así podrían verse los consejos
obreros.


Autómatas, copias y replicadoras
--------------------------------

Aun así, ¿es necesaria la planificación?  Los esquemas de planificación
neo-socialistas centralizados tanto como sus contrapartes las
consejistas descentralizadas toman las computadoras como instrumentos de
cálculo y de medición, particularmente en la medición del trabajo.  Su
objetivo es abolir la explotación capitalista retornándole a las
trabajadoras el valor completo de su tiempo de trabajo.  Sin embargo
existe otra línea del futurismo comunista que entiende a las
computadoras no tanto como instrumentos de planificación sino como
máquinas de abundancia.  Podríamos decir que existen dos formas de
ganarle a la catalaxia capitalista de Hayek. La primera es superarla en
capacidad de cálculo.  La segunda es demolerla: la escasez es
reemplazada por plenitud, terminando con la necesidad de los precios
o la planificación.  Para las marxistas, la "abundancia" cierra la
transición desde la fase "baja" del comunismo, que todavía debe resolver
los problemas de la escasez, a una fase más elevada bajo el principio
"de cada quien según su capacidad, a cada quien según su necesidad". Una
metáfora popular para las condiciones tecnológicas necesarias para este
último momento es el "replicador" de _Star Trek_, que automáticamente
y con energía infinita provee a las necesidades humanas [@fraise-2011].
Este ensayo no intenta adjudicar qué nivel de satisfacción de
necesidades debería ser considerado "suficiente" o qué combinación de
crecimiento y redistribución es adecuada para alcanzarlo.  Este
seguramente será el problema de las planificadoras colectivas del
futuro.  Sin embargo, identificamos tres tendencias cibernéticas que
apuntan hacia esta fase "alta" del comunismo: la automatización, la
copia y la producción de pares.

La automatización ha sido lo más central para el imaginario comunista.
Su postulado clásico es el ahora famoso "Fragmento sobre las máquinas"
de los Grundrisse, donde al observar la fábrica industrial de su tiempo,
Marx [-@marx-1973, pp. 690-711] predice que la tendencia del capital
hacia la mecanización de la producción y la eliminación consecuente del
trabajo asalariado hará explotar el sistema.  El fundador de la
cibernética, Norbert Weiner [-@weiner-1950] vio que su mayor
consecuencia sería la eliminación computarizada del trabajo.  Esta tesis
digital sobre el "fin del trabajo" ha sido desarrollada de manera muy
clara por pensadoras como Andre Gorz [-@gorz-1985] y Jeremy Rifkin
[-@rifkin-1995].  Sin embargo, a fines del siglo XX el capital había
evitado notoriamente este escenario.  Lejos de automatizar por completo
el trabajo, sale a buscar tanto las reservas globales de trabajo barato,
seguido por una "marcha de los sectores" que impulse un frente móvil de
_comodificación_[^ndt-comodificacion] del trabajo a través de la
agricultura, la industria y los servicios.

[^ndt-comodificacion]: _Transformación de bienes, servicios, ideas
y otros conceptos en mercancía. (Nota de traducción)_

Desde el 2000, no obstante, el debate sobre la automatización se ha
renovado.  La reducción continua de los costos computacionales, las
mejoras en las tecnologías visuales y táctiles, las inversiones
militares en drones y vehículos autónomos para las guerras posteriores
al 11 de septiembre, las demandas salariales de las trabajadoras en
China, India y otras fuentes de trabajo barato ha disparado una "nueva
ola de robots... mucho más adeptas que aquellas utilizadas comúnmente
por las automotrices y otras fábricas pesadas", más flexibles y fáciles
de entrenar, reemplazando trabajadoras no solo en la manufactura sino
también en los procesos de distribución, circulación y servicios, como
el almacenamiento, los _call centers_ e incluso el cuidado de personas
ancianas [@markoff-2012].  Erik Brynjolfsson y Andrew McAfee
[-@brynjolfsson-mcafee], economistas del MIT, han dado la alarma sobre
"el ritmo y la escala de esta usurpación de las capacidades humanas" que
está alcanzando un nuevo nivel con "profundas implicaciones económicas".
Estas preocupaciones se están haciendo eco entre los economistas
_mainstream_ [@klugman-2012].

Dentro del capital, la automatización amenaza a las trabajadoras con
desempleo y aceleración de la producción.  Si, sin embargo, no hubiese
una tendencia estructural dominante hacia el incremento en la
productividad que lleve al desempleo o no reduzca el tiempo de trabajo,
la automatización podría disminuir cada vez más el tiempo requerido por
los espacios de trabajo formales.  En un marco comunista que proteja el
acceso al valor de uso de bienes y servicios, la robotización crea el
prospecto del salto del reino de la necesidad al de la libertad.
Reintroduce el objetivo, bloqueado tanto por el experimento soviético
stajanovita y por el gremialismo occidental abocado a la lucha salarial,
de liberar el tiempo del trabajo, con todo lo que esto incluye en
términos de auto-desarrollo humano y compromiso comunal.

Juliet Schor [-@schor-1991] estima que si las trabajadoras
estadounidenses hubieran utilizado sus victorias sobre los incrementos
en la producción en tiempo libre en lugar de salarios más altos, para
los 2000 hubieran tenido una semana laboral de 20 horas. Esto indica la
escala del cambio posible.  La "renta básica" ha figurado entre las
últimas propuestas de la izquierda.  Ciertamente hay críticas para hacer
a esto ya que son propuestas como estrategias reformistas, con el riesgo
de convertirse en un mero servicio social racionalizado para apoyar la
precariedad neoliberal.  Pero sería difícil imaginar un futuro comunista
pleno que no instituya medidas similares para reconocer las reducciones
en el tiempo de trabajo socialmente necesario, hechas posibles por los
avances en la ciencia y la tecnología y que destruyen el problema de
cálculo de Hayek al sustraerle progresivamente la mercancía original
capitalista que es la fuerza de trabajo.

Mientras las robots socavan la centralidad de la relación asalariada, la
Internet presenta una posibilidad paralela que son los bienes sin
precio.  Los economistas _mainstream_ han reconocido desde hace tiempo
las características anómalas de los bienes informacionales no rivales,
que pueden ser copiados infinitamente con costo nulo, circulados
instantáneamente y compartidos sin detrimento de su valor de uso.
Mientras más se digitalizan las producciones intelectuales y culturales,
las tendencias que convierten la Internet en "un espacio de abundancia"
[@siefkes-2012] se han vuelto cada vez más problemáticas para el sistema
de precios.  El capital ha luchado por mantener la forma mercancía en
el ciberespacio, tanto en sus intentos por imponer la propiedad
intelectual, como por tomar los flujos informacionales como aceleradores
publicitarios para otras mercancías. Sin embargo, la corriente hacia la
_decomodificación_[^ndt-decomodificación] ha probado ser inerradicable e
incluso se ha intensificado por la capacidad de conducir su circulación
por fuera de servidores centralmente controlados, a través de redes de
pares.  La piratería, que abarca la mayoría de la música, juegos,
películas y software digitales distribuidos en Asia, África, América
Latina y Europa del Este [@karaganis-2011] es la manifestación
clandestina y criminalizada de esta tendencia. El movimiento del
Software Libre es su expresión organizada.

[^ndt-decomodificación]: Del ingles _decommodification_, debe
  interpretarse como la intención de transformar un bien, servicio
  o idea en algo inmune a la _comodificación_.  _(Nota de traduccion)_

Este último ha sido el foco de la izquierda libertaria desde la
inauguración de la _Free Software Foundation_ por Richard Stallman en
1984, que publica código bajo la _General Public License_ (GPL)
garantizando a las usuarias la libertad de reutilizarlo, estudiarlo,
modificarlo, redistribuirlo y cambiarlo. Como observa Jacob Rigi
[-@rigi-2012] la llamada "cláusula _copyleft_" de la GPL, que requiere
que cualquier programa que use código GPL sea también GPL, es una
"negación dialéctica" del _copyright_, porque al mismo tiempo que
preserva la propiedad sobre el software la está aboliendo, formulando
"un derecho de propiedad global que incluye a todas".  Este desarrollo
fue elaborado por la organización que hace Linus Torvalds a principios
de los '90 como un método en línea, voluntario, colectivo y cooperativo
para la producción de software libre.  Como dice Rigi [-@rigi-2012], la
combinación de la licencia GPL con la programación colectiva al estilo
de Linux "representa la base del modo de producción de pares".  Rigi ve
en esto una instanciación del "alto comunismo" de Marx que reconoce la
naturaleza colectiva del conocimiento científico y rechaza cualquier
demanda basada en la escasez por la "equivalencia entre la contribución
a la producción social y la participación en el producto social".

El Software Libre ha alcanzado un éxito práctico considerable
[@weber-2004] mientras que la producción de pares se ha desarrollado en
varias direcciones, con posiciones políticas que van desde el
_libertarianismo_[^ndt-libertarian] capitalista a posturas progresistas
sobre la nueva "riqueza de las redes" [@benkler-2006] como
suplementarias y compatibles con los mercados.  Pero también hay
posturas específicamente comunistas como las del proyecto _Oekonux_
[@meretz-2012].  Incluso la ecuménica _Foundation for P2P Alternatives_
[@bauwens-2012] abarca todo el espectro político.  Sin embargo, aun
cuando se considere al software libre y la producción de pares como un
modo de producción germinal, las dificultades para cultivar esta semilla
se han vuelto visibles.  Una de estas dificultades es la facilidad
relativa con la que el capital ha incorporado esta semilla como una
contribución a los procesos de formación de mercancías posteriores.  En
efecto, puede decirse que la Web 2.0 ha actuado como contenedora de la
"nueva" producción de pares y sus métodos de circulación, manteniéndolos
dentro de la cáscara de las "viejas" formas de mercancía capitalistas.
El otro problema ha sido lo que Graham Seaman [-@seaman-2002] denomina
"el problema del lavarropas", es decir la distancia entre la producción
virtual y la material, el software cornucópico y la producción
industrial, que parece restringir las prácticas de pares, aun
progresivas, a un pequeño subconjunto de la actividad económica total.

[^ndt-libertarian]: Mantenemos el original _libertarian_ para no
confundir con libertarismo. (Nota de la traducción.)

Durante la última década, no obstante, esta brecha se ha reducido por el
rápido desarrollo de formas de micro-fabricación controlada por
computadora, de las que la impresión tridimensional aditiva es la más
famosa.  Pero existen otras, incluyendo las micro-fresadoras
sustractivas y otros dispositivos de ingeniería miniaturizados
y digitalizados que ponen la capacidad industrial dentro del alcance de
_hacklabs_, hogares y comunidades pequeñas.  Esto ha provisto las bases
para la emergencia de un movimiento _maker_ que vincula estas unidades
de manufactura digital con la circulación en red del diseño, sugiriendo
a algunas que "el modo de producción de pares puede extenderse a la
mayor parte de las ramas de la producción material" [@rigi-2012].  Estas
tecnologías también están asociadas a la proliferación de robots
y autómatas de pequeña escala.  De hecho el cáliz sagrado del movimiento
_maker_ es la replicadora auto-replicante, la máquina de von Neumann
perfecta.  La extrapolación de estas tendencias pone a las _fabbers_
y replicadoras de la imaginación de la ciencia ficción mucho más cerca
de realizarse de lo que hasta ahora parecía posible.

Hasta las _makers_ más orientadas al mercado no dejan de reconocer que
estos desarrollos parecen retornar los medios de producción a manos
populares [@doctorow-2009; @anderson-2012].  Pero como sugiere el
ejemplo del Software Libre, no existe una lógica comunizante intrínseca
al movimiento _maker_, lo que podría muy fácilmente resultar tanto en
una proliferación de micro-emprendorismo como en un común
micro-industrial.  En su crítica a las entusiastas progresistas de la
producción de pares, Tony Smith observa que el desarrollo pleno de la
producción de pares basada en los comunes es "incompatible con las
relaciones capitalistas de propiedad y producción" [@smith-2012].
Mientras estas relaciones persistan, aquellas involucradas en la
producción de pares voluntaria continuarán siendo explicadas en los
términos de la relación salarial de la que dependen.  Sus creaciones
continuarán siendo apropiadas por el capital como "regalos libres" y el
desarrollo más amplio de estos proyectos continuará estando famélico de
recursos.

Sin embargo, en un mundo donde las inversiones se determinen sin
favorecer sistemáticamente la formación de mercancía del conocimiento
y sin la posibilidad de combinar los bienes comunes con el conocimiento
privativo, la "inmensa promesa emancipadora" de la producción de pares
podría realizarse [@smith-2012].  Como señala Smith, el capital contiene
dentro de sí una tendencia a desarrollar tecnologías "que permiten
a ciertos tipos de valores de uso ser distribuidos en cantidades
ilimitadas a individuos con costos marginales cercanos a cero"
[@smith-2006].  "En cualquier forma de socialismo digno de su nombre,
los costos de la infraestructura y el trabajo socialmente necesario para
producir productos como estos serán socializados y los productos serán
distribuidos directamente como bienes públicos gratuitos para cualquiera
que los quiera."  Aunque Smith es escéptico de que esta tendencia
prevalezca "en el futuro cercano" a través de toda la economía, concede
que si así lo hiciera, la experiencia soviética "plagada por las
dificultades de la escasez" se volvería "completamente irrelevante para
el proyecto socialista" [@smith-2006].


Infraestructuras de conocimiento en el Antropoceno
--------------------------------------------------

Sin embargo, Fraise [-@fraise-2011] sugiere que una sociedad comunista
de la abundancia con alta automatización, software libre y replicadoras
domésticas necesitará más planificación que nunca antes. No para superar
la escasez sino para resolver los problemas de la abundancia, que hoy en
día amenazan las condiciones de la vida misma. El cambio climático
global y un conjunto de problemas ecológicos intervinculados son un
desafío para todas las posturas que hemos discutido.  La bio-crisis
llama a la planificación, o al cálculo, pero un cálculo de acuerdo
a métricas que midan límites, umbrales y grados de la supervivencia de
las especies, humanas o no.  Al discutir los imperativos de una
planificación eco-socialista, Michael Lowy [-@lowy-2009] señala que
requeriría una dirección social mucho más comprensiva que el mero
"control obrero" o incluso la reconciliación negociada entre los
intereses de las trabajadoras y las consumidoras que sugieren abordajes
como los de _Parecon_.  Más bien, implica una reconstrucción profunda de
los sistemas económicos, incluyendo la abolición de ciertas industrias,
como la pesca industrializada o la tala indiscriminada, la reformulación
de los métodos de transporte, "una revolución en el sistema energético"
y un impulso hacia el "comunismo solar" [@lowy-2009].

Tales transformaciones pondrían a la cibernética sobre dos ejes mayores,
ambos contribuyendo a la bio-crisis actual y a la vez como medios
potenciales para su resolución.  En el primero de estos ejes, los costos
ecológicos de las tecnologías digitales nominalmente "limpias" se han
vuelto cada vez más aparentes:  los requisitos en energía eléctrica de
los centros de datos de la computación en la nube, la demanda de agua
limpia y minerales de la manufactura de microchips y la prodigiosa
cantidad de basura electrónica tóxica resultante.  Convertir a todas las
casas en mini-fábricas _fablab_ solo aceleraría la muerte por
calentamiento planetario.  Contrariamente a todas las nociones
idealistas de los mundos virtuales, la cibernética es parte inevitable
del mismo sistema industrial cuyas operaciones deben ser puestas bajo
escrutinio en un nuevo sistema de regulación metabólica que apunte a una
abundancia tanto roja como verde.


Sin embargo, los sistemas cibernéticos son también una parte potencial
de cualquier resolución de la bio-crisis.  A Vast Machine \[Una máquina
vasta\] de Paul Edward [-@edward-2010] analiza el sistema global de
medición y proyección climatológica, es decir el aparato de estaciones
meteorológicas, satélites, sensores, registros digitales y simulaciones
por computadora masivas que se originaron, como la Internet, durante la
planificación estadounidense de la Guerra Fría sobre el que descansa
nuestro entendimiento del calentamiento global.  Esta infraestructura
genera información tan vasta en cantidad y en diversidad de plataformas,
calidad y formas que solo puede ser comprendida a través del análisis
computacional.  El conocimiento sobre el cambio climático depende de
modelos computacionales: simulaciones sobre el clima, modelos de
re-análisis, que recrean la historia climática a partir de datos
históricos y los modelos de datos que combinan y ajustan mediciones de
distintas fuentes.

Al revelar la contingencia de las condiciones para la supervivencia de
las especies y la posibilidad de su cambio antropogénico estas
"infraestructuras de conocimiento" sobre gente, artefactos e
instituciones [@edwards-2010] que no solo miden el clima sino que
también monitorean la acidificación de los océanos, la deforestación,
pérdida de especies o la disponibilidad de agua, también se revela el
punto ciego de la catalaxia de Hayek, donde las bases mismas de la
existencia humana figuran como un "externalidad" arbitraria.  El así
llamado "capital verde" intenta subordinar tales bio-datos a las señales
de precios.  Resulta fácil señalar la falacia en ponerle precio a
eventos no-lineales y catastróficos.  ¿Cuál es el precio apropiado para
el último tigre o el nivel de emisiones de carbono que dispara la
liberación incontrolable de metano?  Pero los bio-datos y las
bio-simulaciones tienen que estar incluidas en cualquier noción de
planificación colectiva comunista.  Mientras este proyecto apunte a un
reino de la libertad que escape de la necesidad del trabajo, los bienes
comunes que cree deberán serlo con energías más limpias y el
conocimiento libre que circule debe priorizar la regulación metabólica.
Los problemas de la remuneración apropiada por el tiempo de trabajo
deben integrarse a los cálculos ecológicos.  Ninguna bio-salida que no
reconozca las aspiraciones de millones de proletarias planetarias de
escapar de la desigualdad y de la miseria tendrá éxito.  Pero también las
mediciones laborales mismas deben ser repensadas como parte de un
cálculo más amplio de uso de energía compatible con la supervivencia
colectiva.


Conclusión: ¿Por el K-omunismo?
-------------------------------

En la famosa, o notoria, comparación entre "el peor de los arquitectos"
y "la mejor de las abejas", Marx [-@marx-1964] veía al primero
distinguirse por su habilidad por "erigir en la imaginación" la
estructura a crear.  Hoy en día, con nuestro conocimiento sobre las
comunidades de abejas, esta distinción hiede a antropocentrismo.  Aun
así, junto a abejas, castores y otros primates, la especie humana
manifiesta una capacidad de planificación hipertrófica.  La experiencia
soviética de la que las cibernéticas caracterizadas en Abundancia roja
formaban parte fue solo una instanciación estrecha, históricamente
específica y trágica de esta capacidad, cuyo autoritarismo ocluye el
punto más crucial del concepto marxista de planificación.  Es decir, su
propósito es ser un medio de elección comunal con una variedad de
trayectorias entre las cuales podría darse un devenir colectivo en tanto
especie humana [@dyer-witheford-2004].

Un nuevo comunismo cibernético, en sí una de estas opciones,
involucraría algunos de los elementos siguientes: el uso de las
super-computadoras más avanzadas para calcular algorítmicamente el
tiempo de trabajo y los recursos necesarios a niveles globales,
regionales y locales entre múltiples caminos posibles de desarrollo
humano;  la selección entre estos caminos mediante una discusión
democrática en capas, conducida a través de asambleas que incluyan redes
digitales socializadas y enjambres de agentes de software; actualización
a velocidad de la luz y revisión constante de los planes seleccionados
por flujos de _big data_ tomados de la producción y el consumo;  el
pasaje de cada vez más bienes y servicios al reino de lo libre o la
producción directa de valores de uso una vez que la automatización y los
comunes _copyleft_ de pares se establezca; una información del proceso
completo por parámetros establecidos a través de simulaciones, sensores
y sistemas satelitales que midan y monitoreen el intercambio metabólico
de la especie con el ambiente planetario.

Este sería un comunismo heredero de los "soviets más electricidad" de
Lenin, con raíces en el futurismo rojo, el constructivismo, la
tectología y la cibernética, unidas a los imaginarios de ciencia ficción
de izquierda de autoras como Iain M. Banks, Ken McLeod y Chris Moriarty.
Sería una matriz social llevando a formas cada vez más sofisticadas de
inteligencia artificial a convertirse en aliadas de la emancipación
humana.  Para aquellas que temen la marcha de las máquinas hay este
consuelo:  cualquier singularidad que emerja de estas redes no será la
de entidades programadas para la expansión ilimitada del lucro y la
defensa militar de la propiedad, sino para el bienestar humano y la
protección ecológica.  Un comunismo tal está en consonancia con una
política aceleracionista de izquierda que, en lugar de
anarco-primitivismos, localismos defensivos y nostalgia fordista, "puja
hacia un futuro más moderno, una modernidad alternativa que el
neoliberalismo es inherentemente incapaz de generar"
[@williams-srnicek-2013].  Si necesita un nombre, puede tomarse el
prefijo K- con el que algunas designan las empresas kibernéticas
y llamárselo _komunismo_.  El espacio de posibilidad para tal comunismo
existe ahora entre las líneas convergentes del colapso de la
civilización y la consolidación capitalista.  En este pasadizo
estrechándose el comunismo no surgirá de ninguna lógica teleológica sino
pieza por pieza a través de innumerables conflictos y rupturas sociales,
como un modo de producción post-capitalista emergiendo en el contexto de
la crisis masiva del siglo XXI, ensamblándose a sí mismo desde un
centenario de historia comunista de computación no-lineal, para crear
las plataformas de una futura abundancia roja.

Bibliografía
============

Albert, M. (2003) Parecon: Life After Capitalism. New York: Verso.

Albert, M. & Hahnel, R. (1991) Looking Forward: Participatory Economics for the Twenty First Century. Boston: South End Press.

Anderson, C. (2012) Makers: The New Industrial Revolution.  Toronto: Signal.

Bauwens, M. (2005) ‘The Political Economy of Peer Production’, CTheory, January 12: http://www.ctheory.net/articles.aspx?id=499

Benkler, Y. (2006) The Wealth of Networks. New York: Yale University Press.

Brynjolsson, E, & McAfee, A. (2011) Race Against the Machine. Lexington, MA: Digital Frontier.

Cabello, F. et al. (2013) ‘Towards a Free Federated Social Web: Lorea Takes the Networks’, in G. Lovink & M. Rasch (eds), Unlike Us Reader: Social Media Monopolies and Their Alternatives.  Amsterdam: Institute of Network Cultures.

Castells, M. (2000) End of Millennium.  Oxford: Oxford University Press.

Castoriadis, C. (1972) ‘Workers' Councils and the Economics of a Self-Managed Society’: http://www.marxists.org/archive/castoriadis/1972/workerscouncils.htm

Cockshott, P. & Cottrell A. (1993) Towards a New Socialism.  London: Spokesman Books.

Cockshott, P., & Zachariah, D. (2012) Arguments For Socialism, June 2: www.lulu.com

Cockshott, P., Cottrell, A., Dieterich, H. (2010) ‘Transition to 21st Century Socialism in the European Union’: http://reality.gn.apc.org/econ/Berlinpaper.pdf

Dean, J. (2012) The Communist Horizon. London: Verso.

Dieterich, H. (2006) Der Sozialismus des 21. Jahrhunderts – Wirtschaft, Gesellschaft und Demokratie nach dem globalen Kapitalismus. Berlin: Homilius.

Doctorow, C. (2009) Makers. New York: Tor.

Dorrier, J. (2012) ‘The Race to a Billion Billion Operations Per Second: An Exaflop by 2018?’, SingularityHUB, January 11: http://singularityhub.com/2012/11/01/the-race-to-a-billionbillion-operations-per-second-an-exaflop-by-2018/

Dyer-Witheford, N. (2004) ‘1844/2004/2044: The Return of Species-Being’, Historical Materialism. 13(4): 3-25.

Economist (2012). ‘Welcome to the thingternet: Things, rather than people, are about to become the biggest users of the internet.’ The Economist, November 21: http://www.economist.com/news/21566428-things-rather-peopleare-about-become-biggest-users-internet-welcome.

Edwards, P. (2010) A Vast Machine: Computer Models, Climate Data, and the Politics of Global Warming. Cambridge, MA: MIT Press.

Franceschet, M. (2010) ‘PageRank: Standing on the Shoulders of Giants’, Cornell University Library, February 15: http://arxiv.org/abs/1002.2858

Gerovitch, S. (2008) ‘InerNyet: Why the Soviet Union Did Not Build a Nationwide Computer Network’, History and Technology 24 (4): 335-350.

Gorz, A. (1985) Paths to Paradise: On the Liberation from Work.  London: Pluto Press.

Greenwood, D. (2007) ‘From Market to Non-Market: An Autonomous Agent Approach to Central Planning’, Knowledge Engineering Review 22 (4): 349-360.

Hahnel, R. (2008) ‘Robin Hahnel Answers Various Criticisms of Participatory Economics’, ZNet, November 19: http://www.zcommunications.org/robin-hahnel-answers-variouscriticisms-of-participatory-economics-by-robin-hahnel

Haiven, M. & Stoneman, S. (2009) ‘Wal-Mart: The Panopticon of Time’, Globalization Working Papers, Institute on Globalization and the Human Condition: McMaster University, April: http://www.academia.edu/1474872/WalMart_The_panopticon_of_time

Hardt, M. & Negri, A. (2009) Commonwealth. Cambridge, MA: Harvard University

Press.  Harvey, D. (2010) ‘Organizing for the Anti-Capitalist Transition: Talk Given at the World Social Forum 2010, Porto Alegre’, Reading Marx's Capital with David Harvey, http://davidharvey.org/2009/12/organizing-for-the-anti-capitalisttransition/

Hayek, F. (ed.) (1935) Collectivist Economic Planning. London: Routledge.

Hayek, F. (1976) Law, Legislation and Liberty v. 2: The Mirage of Social Justice. Chicago: University of Chicago Press.

Hayek, F. (1945) ‘The Use of Knowledge in Society’, American Economic Review 35 (4): 519-530.

Hayek, F. (1944) The Road to Serfdom. Chicago: University of Chicago.

Hui, Y. & Halpin, H. (2013) ‘Collective Individuation: The Future of the Social Web’, in G. Lovink & M. Rasch (eds), Unlike Us Reader: Social Media Monopolies and Their Alternatives. Amsterdam: Institute of Network Cultures.

Jameson, F. (2009) Valences of the Dialectic. London: Verso.

Karaganis, J. (ed.) (2011) Media Piracy in Emerging Economies. New York: Social Science Research Council.

Kephart, J. (2002) ‘Software Agents and the Route to the Information Economy’, Proceedings of the National Academy of Sciences of the United States of America, vol. 99, no. Suppl 3, May 14:7207-7213.

Krugman, P. (2012) ‘Robots and Robber Barons’, New York Times (December 6): http://www.nytimes.com/2012/12/10/opinion/krugman-robotsand-robber-barons.html?_r=0

Lange, O. (1967) ‘The Computer and the Market’, in C. H.  Feinstein (ed.), Socialism, Capitalism and Economic Growth: Essays Presented to Maurice Dobb. Cambridge: Cambridge University Press.

Lichtenstein, N. (ed.) (2006) Wal-Mart: The Face of Twenty-First Century Capitalism. New York: New Press.

Lovink, G. & Rasch, M. (eds) (2013) Unlike Us Reader: Social Media Monopolies and Their Alternatives. Amsterdam: Institute of Network Cultures.

Lowy, M. (2006) ‘Ecosocialism and Democratic Planning’, in L.  Panitch & C. Leys (eds), Socialist Register 2007. London: Merlin.

Marx, K. (1964) Economic and Philosophic Manuscripts of 1844. New York: International Publishers.

Marx, K. (1970) Critique of the Gotha Program. Moscow: Progress Publishers.  Marx, K. (1973) Grundrisse. Harmondsworth: Penguin.

Marx, K. (1977) Capital Vol. 1. New York: Vintage Books.

Medina, E. (2011) Cybernetic Revolutionaries: Technology and Politics in Allende's Chile. Cambridge, MA: MIT Press.

Mirowski, P. (2002) Machine Dreams: Economics Becomes a Cyborg Science. Cambridge: Cambridge University Press.

Mirowski, P. (ed.) (2009) The Road from Mont Pelerin: The Making of the Neoliberal Thought Collective. Cambridge, MA: Harvard University Press.

Nove, A. (1983) The Economics of Feasible Socialism. London: Allen & Unwin.

Peters, A. (2001) Computer Sozialismus: Gespräche mit Konrad Zuse.  Berlin: Verlag.

Peters, B. (2012) ‘Normalizing Soviet Cybernetics’, Information & Culture 47(2) 145-175.

Rifkin, J. (1995) The End of Work. New York: Putnam.

Rigi, J. (2012) ‘Peer-to-Peer Production as the Alternative to Capitalism: A New Communist Horizon’, Journal of Peer Production 1: http://peerproduction.net/issues/issue-1/invited-comments/anew-communist-horizon/

Schor, J. (1991) The Overworked American: The Unexpected Decline of Leisure. New York: Basic Books.

Seaman, G. (2002) ‘The Two Economies or Why the Washing Machine Question is the Wrong Question’: http://second.oekonuxconference.org/documentation/texts/Seaman.html

Sevignani, S. (2013) ‘Facebook vs. Diaspora: A Critical Study’, in G. Lovink & M. Rasch (eds), Unlike Us Reader: Social Media Monopolies and Their Alternatives. Amsterdam: Institute of Network Cultures.

Shalizi, C. (2012) ‘In Soviet Union, Optimization Problem Solves You’, Crooked Timber (May 30): http://crookedtimber.org/2012/05/30/in-soviet-unionoptimization-problem-solves-you/

Siefkes, C. (2012) ‘Beyond Digital Plenty: Building Blocks for Physical Peer Production’, Journal of Peer Production 1: http://peerproduction.net/issues/issue-1/invitedcomments/beyond-digital-plenty/

Smith, T. (2012) ‘Is Socialism Relevant in the ‘Networked Information Age’? A Critical Assessment of The Wealth of Networks’, in A. Anton & R. Schmitt (eds), Taking Socialism Seriously. Lanham: Lexington.  Smith, T. (2006) Globalisation: A Systematic Marxian Account.  Boston: Brill.

Stallman, R. (2004) Free Software, Free Society. Thissur, India: Altermedia.

Thorburn, E. (2013) ‘Minoritarian Assemblages: Embodied and Machinic Agencies in the New Cycles of Struggle’, Journal of Communication and Critical/Cultural Studies, forthcoming.

von Mises, L. (1935) ‘Calculation in the Socialist Commonwealth’, in F.A. Hayek (ed.), Collectivist Economic Planning. London: Routledge.

Weber, S. (2004) The Success of Open Source. Cambridge, MA: Harvard University Press.

Wiener, N. (1950) Human Use of Human Beings: Cybernetics and Society. Boston: Houghton Mifflin.

Wikipedia. (2013a) ‘TOP 500’: http://en.wikipedia.org/wiki/TOP500 Wikipedia.

(2013b) ‘Software agents’: http://en.wikipedia.org/wiki/Software_agent

Williams, A. & Srnicek, N. (2013) ‘#ACCELERATE MANIFESTO for an Accelerationist Politics’ (14 May): http://criticallegalthinking.com/2013/05/14/acceleratemanifesto-for-an-accelerationist-politics

Williams, R. (1983) Towards 2000. London: Chatto & Windus.
